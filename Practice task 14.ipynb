{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 15: \"Обучение с подкреплением 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Намит Максим Михайлович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  FrozenLake\n",
    "\n",
    "\n",
    "<img src=\"http://vignette2.wikia.nocookie.net/riseoftheguardians/images/4/4c/Jack's_little_sister_on_the_ice.jpg/revision/latest?cb=20141218030206\" alt=\"a random image to attract attention\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.18.3.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from gym) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from gym) (1.19.5)\n",
      "Collecting pyglet<=1.5.15,>=1.4.0\n",
      "  Downloading pyglet-1.5.15-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow<=8.2.0 in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from gym) (8.2.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from gym) (1.6.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gym: filename=gym-0.18.3-py3-none-any.whl size=1657516 sha256=d97c7f68d07b0052436fe1e93ce16b3692306aefd0d4c91faf2a7d9fa83b471e\n",
      "  Stored in directory: /home/namitmax/.cache/pip/wheels/1a/ec/6d/705d53925f481ab70fd48ec7728558745eeae14dfda3b49c99\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, gym\n",
      "Successfully installed gym-0.18.3 pyglet-1.5.15\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "#create a single game instance\n",
    "env = gym.make(\"FrozenLake-v0\")\n",
    "\n",
    "#start new game\n",
    "env.reset();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "# display the game state\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### legend\n",
    "\n",
    "![img](https://cdn-images-1.medium.com/max/800/1*MCjDzR-wfMMkS0rPqXSmKw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "Подберите значения alpha и epsilon и найдите приближение оптимальной Q-функции для Frozen Lake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearn:\n",
    "    def __init__(self, actions, epsilon=0.1, alpha=0.2, gamma=0.9):\n",
    "        self.q = {}\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.actions = actions\n",
    "\n",
    "    def getQ(self, state, action):\n",
    "        return self.q.get((state, action), 0.0)\n",
    "\n",
    "    def learnQ(self, state, action, reward, value):\n",
    "        oldv = self.q.get((state, action), None)\n",
    "\n",
    "        if oldv is None:\n",
    "            self.q[(state, action)] = reward\n",
    "        else:\n",
    "            self.q[(state, action)] = oldv + self.alpha * (value - oldv)\n",
    "\n",
    "    def chooseAction(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            action = random.choice(self.actions)\n",
    "        else:\n",
    "            q = [self.getQ(state, a) for a in self.actions]\n",
    "            maxQ = max(q)\n",
    "            count = q.count(maxQ)\n",
    "            if count > 1:\n",
    "                best = [i for i in range(len(self.actions)) if q[i] == maxQ]\n",
    "                i = random.choice(best)\n",
    "            else:\n",
    "                i = q.index(maxQ)\n",
    "\n",
    "            action = self.actions[i]\n",
    "        return action\n",
    "\n",
    "    def learn(self, state1, action1, reward, state2):\n",
    "        maxqnew = max([self.getQ(state2, a) for a in self.actions])\n",
    "        self.learnQ(state1, action1, reward, reward + self.gamma*maxqnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode_qlearn_learn(env, qlearn, gamma = 1.0, render = False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        qlearn.learn(obs, action, reward, obs_new)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode_qlearn(env, qlearn, gamma = 1.0, render = False):\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        action = qlearn.chooseAction(obs)\n",
    "        obs_new, reward, done, _ = env.step(action)\n",
    "        obs = obs_new\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qlearn(env, qlearn, gamma = 1.0,  n = 100):\n",
    "    scores = [\n",
    "            run_episode_qlearn(env, qlearn, gamma = gamma, render = False)\n",
    "            for _ in range(n)]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best 0.52 alpha= 0.3333333333333333  eps= 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "best_alpha = 0\n",
    "best_eps = 0\n",
    "best = 0\n",
    "N = 500\n",
    "for alpha in np.linspace(0, 0.5, 10):\n",
    "    for eps in np.linspace(0, 0.5, 10):\n",
    "        qlearn = QLearn(actions=range(env.env.nA), gamma=1, epsilon=eps, alpha=alpha)\n",
    "        for i in range(N):\n",
    "            run_episode_qlearn_learn(env, qlearn, gamma=1)\n",
    "        result = evaluate_qlearn(env, qlearn, n=N)\n",
    "        if result > best:\n",
    "            best_alpha = alpha\n",
    "            best_eps = eps\n",
    "            best = result\n",
    "    clear_output()\n",
    "    print('best', best, 'alpha=', best_alpha, ' eps=', best_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top reward = 0.52 with alpha = 0.3333333333333333  and eps = 0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "print('top reward =', best, 'with alpha =', best_alpha, ' and eps =', best_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlearn = QLearn(actions=range(env.env.nA), gamma=1, epsilon=best_eps, alpha=best_alpha)\n",
    "for i in range(N):\n",
    "    run_episode_qlearn_learn(env, qlearn, gamma=1)\n",
    "result = evaluate_qlearn(env, qlearn, n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.452"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode_qlearn(env, qlearn, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задание 2.\n",
    "Обучите сеть DQN для среды http://gym.openai.com/envs/Pong-v0/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting atari_py\n",
      "  Using cached atari-py-0.3.0.tar.gz (540 kB)\n",
      "Requirement already satisfied: numpy in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from atari_py) (1.19.5)\n",
      "Requirement already satisfied: six in /home/namitmax/anaconda3/envs/tf_env/lib/python3.7/site-packages (from atari_py) (1.15.0)\n",
      "Building wheels for collected packages: atari-py\n",
      "  Building wheel for atari-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for atari-py: filename=atari_py-0.3.0-cp37-cp37m-linux_x86_64.whl size=2538698 sha256=08bace7d61f78603fee73c929dcfdfee5f5bf53a5cb3cfbeba543f1722dd7db6\n",
      "  Stored in directory: /home/namitmax/.cache/pip/wheels/a8/a6/7f/dea737dfb8dfa294a1c6ddd3c005ff5d7e06ab105115add079\n",
      "Successfully built atari-py\n",
      "Installing collected packages: atari-py\n",
      "Successfully installed atari-py-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install atari_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import gym\n",
    "import numpy as np \n",
    "import random\n",
    "\n",
    "env = gym.make('Pong-v0').unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_screen():\n",
    "    screen = env.render(mode='rgb_array')\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    return screen\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1 = 210\n",
    "dim2 = 160\n",
    "dim3 = 3\n",
    "\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, outputs = 3):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=4, stride=3)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=4, stride=3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(1120, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, dim3, dim2, dim1))\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "n_actions = 3\n",
    "policy_net = DQN()\n",
    "target_net = DQN()\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)))\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "for i_episode in range(num_episodes):\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    print(\"# episode\", i_episode)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward])\n",
    "\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            clear_output()\n",
    "            plt.figure(figsize=(4,5))\n",
    "            plt.imshow(get_screen().squeeze(0).numpy(),\n",
    "                       interpolation='none')\n",
    "            plt.show()\n",
    "            break\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
